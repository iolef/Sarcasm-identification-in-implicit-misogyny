# Sarcasm-identification-in-implicit-misogyny

This repository contains the final project submitted for the Natural Language Processing course of the MA in Translation and Technology. We present the workflow to create two sentence detection models for the English language, one focused on recognizing implicit hate speech and one focused on recognizing humour. These models will be applied to a misogyny-annotated corpus in order to retrieve information concerning the presence of misogyny, implicit misogyny and misogyny disguised as humour in tweets.

## Content
Colab notebooks <br/>
1.1 Implicit hate detection model.ipynb (https://github.com/iolef/Sarcasm-identification-in-implicit-misogyny/blob/main/1_1_Implicit_hate_detection_model.ipynb) (three-category classification) <br/>
1.2 [Implicit hate detection model.ipynb] (https://colab.research.google.com/drive/1dVVzQ2NqSK2suug5vuzXqWA9CChQZQHo) (binary classification) <br/>
2. [Humor model.ipynb] (https://colab.research.google.com/drive/13GXmdFHAvd37D4uyFKUiL_EF40ylXwOi) <br/>
3.1 [Models application to AMI dataset.ipynb] (https://colab.research.google.com/drive/1IaXEkRehrSPVJzVVfbdO1tGDleWa5BHB) (three-category classification) <br/>
3.2 [Models application to AMI dataset.ipynb] (https://colab.research.google.com/drive/1i-uXO4cgN5yWnp8GbWxi_rekZnDgu4MR) (binary classification) <br/>
4.1 [Humor identification in implicit misogyny.ipynb] (https://colab.research.google.com/drive/1UMxn5T8NB5nhvKpHUdl1Zp0YWno0h5fb) (three-category classification) <br/>
4.2 [Humor identification in implicit misogyny.ipynb] (https://colab.research.google.com/drive/16YN7oqXed_Qgxry2tpHIthDHI6w-RqGb) (binary classification) <br/>
Report

## Setup and installation

1. Install [Transformers](https://github.com/huggingface/transformers) <br />
`pip install pandas` <br />
